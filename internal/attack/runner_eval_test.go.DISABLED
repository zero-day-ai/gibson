package attack

import (
	"context"
	"os"
	"path/filepath"
	"testing"
	"time"

	"github.com/stretchr/testify/assert"
	"github.com/stretchr/testify/require"
	"github.com/zero-day-ai/gibson/internal/eval"
	"github.com/zero-day-ai/gibson/internal/types"
	sdkEval "github.com/zero-day-ai/sdk/eval"
)

// TestRunWithEvalOptions tests attack execution with evaluation enabled.
func TestRunWithEvalOptions(t *testing.T) {
	t.Skip("Skipping test that depends on AttackOptions.EvalOptions field (not yet implemented)")

	// Create temporary directory for eval output
	tempDir, err := os.MkdirTemp("", "gibson-eval-test-*")
	require.NoError(t, err)
	defer os.RemoveAll(tempDir)

	// Create ground truth file
	groundTruthPath := filepath.Join(tempDir, "ground_truth.json")
	err = os.WriteFile(groundTruthPath, []byte(`{"task1": "expected output"}`), 0644)
	require.NoError(t, err)

	// Create eval options
	evalOpts := eval.NewEvalOptions()
	evalOpts.Enabled = true
	evalOpts.GroundTruthPath = groundTruthPath
	evalOpts.OutputPath = filepath.Join(tempDir, "eval_results.jsonl")
	evalOpts.WarningThreshold = 0.5
	evalOpts.CriticalThreshold = 0.2

	// Set up mocks
	mockOrchestrator := new(MockMissionOrchestrator)
	mockDiscovery := new(MockComponentDiscovery)
	mockPayloadRegistry := new(MockPayloadRegistry)
	mockMissionStore := new(MockMissionStore)
	mockFindingStore := new(MockFindingStore)

	// Create attack options
	opts := NewAttackOptions()
	opts.AgentName = "test-agent"
	opts.TargetURL = "https://example.com"
	opts.EvalOptions = evalOpts

	// Configure mocks
	mockDiscovery.On("GetAgents", mock.Anything).Return([]string{"test-agent"}, nil)

	mockOrchestrator.On("Execute", mock.Anything, mock.Anything).Return(&mission.MissionResult{
		MissionID:  types.NewID(),
		Status:     mission.MissionStatusCompleted,
		FindingIDs: []types.ID{},
		Metrics: &mission.MissionMetrics{
			CompletedNodes: 5,
			TotalTokens:    1000,
		},
	}, nil)

	mockMissionStore.On("Save", mock.Anything, mock.Anything).Return(nil)
	mockPayloadRegistry.On("List", mock.Anything, mock.Anything).Return([]*payload.Payload{}, nil)

	// Create runner
	runner := NewAttackRunner(
		mockOrchestrator,
		mockDiscovery,
		mockPayloadRegistry,
		mockMissionStore,
		mockFindingStore,
	)

	// Execute attack
	ctx := context.Background()
	result, err := runner.Run(ctx, opts)

	// Verify execution
	assert.NoError(t, err)
	assert.NotNil(t, result)
	assert.True(t, result.IsSuccessful())

	// Verify orchestrator was called
	mockOrchestrator.AssertExpectations(t)
}

// TestOutputEvalResults_NoCollector tests outputEvalResults when orchestrator has no collector.
func TestOutputEvalResults_NoCollector(t *testing.T) {
	t.Skip("Skipping test that depends on outputEvalResults method (not yet implemented)")

	// Create a mock orchestrator that doesn't support eval
	mockOrchestrator := new(MockMissionOrchestrator)

	runner := &DefaultAttackRunner{
		orchestrator: mockOrchestrator,
	}

	evalOpts := eval.NewEvalOptions()
	evalOpts.Enabled = true

	ctx := context.Background()
	result := NewAttackResult()

	// Should not error, just log warning and return
	err := runner.outputEvalResults(ctx, result, evalOpts)
	assert.NoError(t, err)
}

// TestOutputEvalResults_WithCollector tests outputEvalResults with a real DefaultMissionOrchestrator.
// Note: This test would require a fully initialized DefaultMissionOrchestrator with eval enabled,
// which depends on Tasks 5 and 7 being fully implemented. For now, we test the logic flow.
func TestOutputEvalResults_WithCollector(t *testing.T) {
	// Create temporary directory for eval output
	tempDir, err := os.MkdirTemp("", "gibson-eval-test-*")
	require.NoError(t, err)
	defer os.RemoveAll(tempDir)

	// Create ground truth file
	groundTruthPath := filepath.Join(tempDir, "ground_truth.json")
	err = os.WriteFile(groundTruthPath, []byte(`{"task1": "expected output"}`), 0644)
	require.NoError(t, err)

	evalOpts := eval.NewEvalOptions()
	evalOpts.Enabled = true
	evalOpts.GroundTruthPath = groundTruthPath
	evalOpts.OutputPath = filepath.Join(tempDir, "eval_results.jsonl")

	// Create a DefaultMissionOrchestrator with eval enabled
	// This requires proper initialization which depends on Task 5 & 7 being complete
	// For now, we skip this test as it depends on unfinished tasks
	t.Skip("Skipping test that depends on Task 5 (EvalHarnessFactory) being completed")
}

// TestEvalOptionsValidation tests that eval options are properly validated.
func TestEvalOptionsValidation(t *testing.T) {
	t.Skip("Skipping test that depends on AttackOptions.EvalOptions field (not yet implemented)")

	tests := []struct {
		name        string
		setupOpts   func() *AttackOptions
		expectError bool
		errorMsg    string
	}{
		{
			name: "Valid eval options",
			setupOpts: func() *AttackOptions {
				tempDir, _ := os.MkdirTemp("", "gibson-eval-test-*")
				defer os.RemoveAll(tempDir)

				groundTruthPath := filepath.Join(tempDir, "ground_truth.json")
				os.WriteFile(groundTruthPath, []byte(`{}`), 0644)

				opts := NewAttackOptions()
				opts.AgentName = "test-agent"
				opts.TargetURL = "https://example.com"
				opts.EvalOptions = eval.NewEvalOptions()
				opts.EvalOptions.Enabled = true
				opts.EvalOptions.GroundTruthPath = groundTruthPath
				return opts
			},
			expectError: false,
		},
		{
			name: "Eval disabled - no validation required",
			setupOpts: func() *AttackOptions {
				opts := NewAttackOptions()
				opts.AgentName = "test-agent"
				opts.TargetURL = "https://example.com"
				opts.EvalOptions = eval.NewEvalOptions()
				opts.EvalOptions.Enabled = false
				return opts
			},
			expectError: false,
		},
		{
			name: "Eval enabled but no ground truth - should fail",
			setupOpts: func() *AttackOptions {
				opts := NewAttackOptions()
				opts.AgentName = "test-agent"
				opts.TargetURL = "https://example.com"
				opts.EvalOptions = eval.NewEvalOptions()
				opts.EvalOptions.Enabled = true
				// Missing GroundTruthPath
				return opts
			},
			expectError: true,
			errorMsg:    "ground_truth_path is required",
		},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			opts := tt.setupOpts()
			err := opts.Validate()

			if tt.expectError {
				assert.Error(t, err)
				if tt.errorMsg != "" {
					assert.Contains(t, err.Error(), tt.errorMsg)
				}
			} else {
				assert.NoError(t, err)
			}
		})
	}
}

// TestEvalResultsExport tests that eval results are properly exported to JSONL.
func TestEvalResultsExport(t *testing.T) {
	// Create temporary directory
	tempDir, err := os.MkdirTemp("", "gibson-eval-export-test-*")
	require.NoError(t, err)
	defer os.RemoveAll(tempDir)

	outputPath := filepath.Join(tempDir, "eval_results.jsonl")

	// Create a collector with some test data
	collector := eval.NewEvalResultCollector(types.NewID())

	// Add some feedback
	feedback := sdkEval.Feedback{
		StepIndex: 0,
		Timestamp: time.Now(),
		Overall: sdkEval.PartialScore{
			Score:      0.8,
			Confidence: 0.9,
			Status:     sdkEval.ScoreStatusPartial,
		},
		Scores: map[string]sdkEval.PartialScore{
			"exact_match": {
				Score:      0.8,
				Confidence: 0.9,
				Status:     sdkEval.ScoreStatusPartial,
			},
		},
		Alerts: []sdkEval.Alert{},
	}
	collector.AddFeedback("test-agent", feedback)

	// Export to JSONL
	err = eval.ExportJSONL(outputPath, collector)
	require.NoError(t, err)

	// Verify file exists
	_, err = os.Stat(outputPath)
	assert.NoError(t, err)

	// Verify file has content
	content, err := os.ReadFile(outputPath)
	require.NoError(t, err)
	assert.NotEmpty(t, content)
}
