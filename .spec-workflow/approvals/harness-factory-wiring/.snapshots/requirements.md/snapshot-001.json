{
  "id": "snapshot_1767730164474_as8nels3g",
  "approvalId": "approval_1767730164463_kvhynznty",
  "approvalTitle": "Requirements: HarnessFactory Wiring for E2E Agent Execution",
  "version": 1,
  "timestamp": "2026-01-06T20:09:24.474Z",
  "trigger": "initial",
  "status": "pending",
  "content": "# Requirements Document: HarnessFactory Wiring for End-to-End Agent Execution\n\n## Introduction\n\nThis specification addresses a critical architectural gap preventing end-to-end agent execution with LLM integration in the Gibson framework. Currently, when an attack or mission is executed via the daemon, agents complete instantly (in ~100ms) without making any LLM calls, returning 0 findings and 0 turns. The root cause is that the **MissionOrchestrator** is created without a **HarnessFactory**, which means agents receive a nil harness and cannot access LLMs, tools, memory, or submit findings.\n\nThis spec details the complete wiring needed across the daemon, SDK, and agent ecosystem to enable true LLM-powered security testing.\n\n## Problem Statement\n\n### Current Behavior (Broken)\n1. User runs `gibson attack -a whistler -t http://target.com`\n2. Daemon's attack runner creates a MissionOrchestrator **without** HarnessFactory\n3. Orchestrator calls WorkflowExecutor, which tries to execute agent nodes\n4. Agent receives **nil harness** because no factory was provided\n5. Agent checks for nil harness and returns early with error (or orchestrator returns success without executing)\n6. Attack completes in ~100ms with 0 findings, 0 LLM turns\n\n### Evidence\n- **daemon.go:234**: `orchestrator := mission.NewMissionOrchestrator(d.missionStore)` - No HarnessFactory option passed\n- **orchestrator.go:251-263**: If `harnessFactory == nil`, mission fails with \"harness factory not configured\"\n- **mission_manager.go:197-210**: TODO comment explicitly states refactoring is needed for harness architecture\n- **whistler/main.go:119-123**: Agent checks `if harness == nil` and returns error\n\n### Desired Behavior\n1. User runs `gibson attack -a whistler -t http://target.com`\n2. Daemon creates MissionOrchestrator **with** properly configured HarnessFactory\n3. Orchestrator creates AgentHarness for each agent node via factory\n4. Agent receives fully functional harness with LLM access, tools, memory, findings\n5. Agent executes multi-turn LLM conversation with actual API calls\n6. Attack completes with real findings, token usage, and execution metrics\n\n## Alignment with Product Vision\n\nThis spec directly enables the core value proposition of Gibson: **LLM-powered automated security testing**. Without this fix:\n- No agents can make LLM calls through the daemon\n- No security findings can be discovered automatically\n- The `gibson attack` and `gibson mission run` commands are non-functional\n- The investor demo workflow cannot execute\n\n## Requirements\n\n### Requirement 1: HarnessFactory Initialization in Daemon\n\n**User Story:** As a security engineer, I want the daemon to properly initialize the HarnessFactory during startup so that all agent execution paths have access to LLM providers.\n\n#### Acceptance Criteria\n\n1. WHEN the daemon starts THEN the system SHALL create a HarnessFactory with valid HarnessConfig containing:\n   - LLMRegistry populated with available providers (Anthropic, OpenAI, etc.)\n   - SlotManager configured with default slot requirements\n   - ToolRegistry connected to the etcd component registry\n   - PluginRegistry connected to the etcd component registry\n   - RegistryAdapter for component discovery\n   - FindingStore backed by SQLite database\n   - Logger with daemon context\n\n2. WHEN LLM provider registration fails (e.g., missing API key) THEN the system SHALL:\n   - Log a warning indicating which provider is unavailable\n   - Continue startup with remaining providers\n   - NOT fail daemon startup entirely\n\n3. IF no LLM providers are registered THEN the daemon SHALL:\n   - Log a warning about missing LLM configuration\n   - Allow startup to complete\n   - Return clear error when mission execution is attempted\n\n### Requirement 2: HarnessFactory Wiring to MissionOrchestrator\n\n**User Story:** As a security engineer, I want the MissionOrchestrator to be properly configured with a HarnessFactory so that workflow execution can create harnesses for agents.\n\n#### Acceptance Criteria\n\n1. WHEN the daemon creates a MissionOrchestrator THEN the system SHALL pass:\n   - `WithHarnessFactory(factory)` option with the initialized factory\n   - `WithWorkflowExecutor(executor)` option with a configured executor\n   - `WithEventEmitter(emitter)` option for progress streaming\n\n2. WHEN an attack is started via `gibson attack` THEN the attack runner's orchestrator SHALL:\n   - Have access to the HarnessFactory\n   - Create harnesses for each agent node in the workflow\n   - Provide harnesses with mission-specific context (mission ID, target info)\n\n3. WHEN a mission is started via `gibson mission run` THEN the mission manager's orchestrator SHALL:\n   - Use the same HarnessFactory as the attack runner\n   - Create harnesses with proper memory manager instances per mission\n\n### Requirement 3: SlotManager Configuration\n\n**User Story:** As a security engineer, I want LLM slot resolution to work correctly so that agents can request LLM capabilities by slot name rather than hardcoded model IDs.\n\n#### Acceptance Criteria\n\n1. WHEN the daemon initializes THEN the system SHALL create a SlotManager that:\n   - Maps slot names (e.g., \"primary\", \"vision\", \"reasoning\") to provider configurations\n   - Uses the LLMRegistry to resolve slots to actual providers\n   - Supports fallback resolution when primary provider is unavailable\n\n2. WHEN an agent requests completion on slot \"primary\" THEN the SlotManager SHALL:\n   - Resolve the slot to an available LLM provider\n   - Return provider configuration with model, temperature, max tokens\n   - Track token usage per slot\n\n3. IF a slot cannot be resolved (no matching provider) THEN the system SHALL:\n   - Return clear error: \"slot 'X' could not be resolved to an available provider\"\n   - Include list of registered providers in error context\n\n### Requirement 4: Memory Manager Initialization Per Mission\n\n**User Story:** As a security engineer, I want each mission to have isolated memory storage so that agents can use working memory, mission memory, and long-term memory without cross-mission contamination.\n\n#### Acceptance Criteria\n\n1. WHEN a mission starts THEN the system SHALL create a MemoryManager with:\n   - Mission ID for scoped storage\n   - Database connection for mission-tier persistence (SQLite FTS5)\n   - Working memory tier (in-memory, ephemeral)\n   - Mission memory tier (SQLite, mission-scoped)\n   - Long-term memory tier (vector DB, cross-mission)\n\n2. WHEN the harness factory creates a harness THEN the MemoryManager SHALL:\n   - Be passed to the harness configuration\n   - Provide agent access via `harness.Memory()` method\n   - Support all three tiers: Working(), Mission(), LongTerm()\n\n3. WHEN a mission completes THEN the system SHALL:\n   - Flush pending memory writes\n   - Keep mission-tier data for historical queries\n   - NOT delete working memory (it's ephemeral anyway)\n\n### Requirement 5: Callback Server Integration\n\n**User Story:** As a security engineer, I want external agents (running as separate processes via gRPC) to make harness operations through the callback server so that both internal and external agents have the same capabilities.\n\n#### Acceptance Criteria\n\n1. WHEN an external agent is invoked THEN the callback server SHALL:\n   - Be registered with the harness factory\n   - Provide callback endpoint in agent task parameters\n   - Handle LLM completion requests from agents\n   - Handle tool execution requests from agents\n   - Handle memory operations from agents\n   - Handle finding submissions from agents\n\n2. WHEN an agent calls `harness.Complete()` via callback THEN the system SHALL:\n   - Route the request through the callback manager\n   - Use the daemon's LLM registry for provider resolution\n   - Return completion response through gRPC stream\n\n3. IF callback server is not running THEN external agent execution SHALL:\n   - Fail with clear error: \"callback server not available\"\n   - NOT hang indefinitely waiting for callback endpoint\n\n### Requirement 6: Finding Store Integration\n\n**User Story:** As a security engineer, I want findings discovered by agents to be automatically persisted so that I can review vulnerabilities after mission completion.\n\n#### Acceptance Criteria\n\n1. WHEN the harness factory creates a harness THEN the FindingStore SHALL:\n   - Be connected to the SQLite database\n   - Support immediate finding persistence via `SubmitFinding()`\n   - Assign unique IDs to findings\n   - Associate findings with mission ID\n\n2. WHEN an agent submits a finding via `harness.SubmitFinding()` THEN the system SHALL:\n   - Validate finding structure (severity, description, evidence)\n   - Store finding in database immediately (sync operation)\n   - Queue finding for GraphRAG ingestion (async operation)\n   - Emit finding event for real-time streaming\n\n3. WHEN mission completes THEN findings SHALL:\n   - Be queryable via `gibson findings list --mission <id>`\n   - Include mission ID, agent name, timestamps\n   - Be exportable to JSON, SARIF, CSV formats\n\n### Requirement 7: WorkflowExecutor Integration\n\n**User Story:** As a security engineer, I want workflows with multiple agents to execute correctly with proper harness propagation so that complex multi-agent missions work end-to-end.\n\n#### Acceptance Criteria\n\n1. WHEN the orchestrator executes a workflow THEN the WorkflowExecutor SHALL:\n   - Receive harness from orchestrator for agent node execution\n   - Create child harnesses for sub-agent delegation via factory\n   - Pass target info and mission context to each agent\n\n2. WHEN executing an agent node THEN the executor SHALL:\n   - Look up agent in component registry\n   - Create harness via factory with agent name and mission context\n   - Execute agent with harness and task\n   - Collect agent result (including findings)\n\n3. WHEN an agent delegates to another agent THEN the system SHALL:\n   - Use HarnessFactory.CreateChild() to create child harness\n   - Preserve parent mission context\n   - Share finding store with parent\n   - Isolate working memory\n\n### Requirement 8: End-to-End Attack Execution\n\n**User Story:** As a security engineer, I want `gibson attack -a whistler -t http://target.com` to execute a complete LLM-powered security test and return real findings.\n\n#### Acceptance Criteria\n\n1. WHEN an attack is executed THEN the system SHALL:\n   - Create ephemeral mission with single-agent workflow\n   - Initialize harness with full LLM access\n   - Execute agent with proper harness (not nil)\n   - Make actual LLM API calls (verified by token usage > 0)\n   - Return findings discovered by agent\n\n2. WHEN attack completes successfully THEN the result SHALL include:\n   - `turns_used > 0` (actual LLM conversation turns)\n   - `tokens_used > 0` (actual API token consumption)\n   - `duration` reflecting real execution time (not ~100ms)\n   - `findings` array with any discovered vulnerabilities\n\n3. IF agent execution fails THEN the system SHALL:\n   - Return detailed error message from agent\n   - Include partial results (any findings before failure)\n   - Log error with full context (mission ID, agent name, step)\n\n### Requirement 9: Configuration and Environment\n\n**User Story:** As a security engineer, I want to configure LLM providers through environment variables and config file so that the daemon can access different AI providers.\n\n#### Acceptance Criteria\n\n1. WHEN daemon starts THEN the system SHALL check for LLM configuration:\n   - `ANTHROPIC_API_KEY` environment variable for Anthropic provider\n   - `OPENAI_API_KEY` environment variable for OpenAI provider\n   - Config file `llm` section for model preferences\n\n2. WHEN API key is present THEN the system SHALL:\n   - Initialize provider with the key\n   - Register provider in LLM registry\n   - Make provider available for slot resolution\n\n3. IF no API keys are configured THEN the system SHALL:\n   - Log warning: \"No LLM API keys found - agent execution will fail\"\n   - NOT block daemon startup\n   - Return clear error when LLM operation is attempted\n\n### Requirement 10: External Agent Support\n\n**User Story:** As an agent developer, I want external agents (running as separate gRPC services) to receive fully functional harnesses through the callback mechanism so that custom agents work the same as built-in agents.\n\n#### Acceptance Criteria\n\n1. WHEN the daemon invokes an external agent THEN the system SHALL:\n   - Include callback server address in task parameters\n   - Provide harness context (mission ID, target info) in task\n   - Start agent execution via gRPC Execute RPC\n\n2. WHEN external agent makes harness operation THEN the callback server SHALL:\n   - Receive operation via gRPC (e.g., CompleteRequest)\n   - Look up harness context from mission/agent IDs\n   - Execute operation using daemon's internal harness\n   - Return result via gRPC response\n\n3. WHEN external agent completes THEN the system SHALL:\n   - Receive result via gRPC Execute response\n   - Merge agent findings into mission findings\n   - Update mission metrics (tokens, turns)\n\n## Non-Functional Requirements\n\n### Code Architecture and Modularity\n- **Single Responsibility Principle**: Harness factory creation should be in a dedicated initialization function\n- **Modular Design**: SlotManager, MemoryManager, and FindingStore should be independent components\n- **Dependency Injection**: All dependencies should be injectable for testing\n- **Clear Interfaces**: Factory interface should be clearly defined in SDK for consistency\n\n### Performance\n- HarnessFactory creation should complete in < 100ms\n- Harness creation per agent should complete in < 10ms\n- Memory manager initialization should not block workflow execution\n- Callback server should handle concurrent requests from multiple agents\n\n### Security\n- API keys must not be logged or exposed in error messages\n- Finding storage must be scoped to prevent cross-mission access\n- Callback server must validate agent authentication\n\n### Reliability\n- LLM provider failure should not crash daemon\n- Missing API keys should result in graceful degradation\n- Callback server should handle connection drops gracefully\n\n### Observability\n- All harness operations should be traceable via OpenTelemetry\n- Token usage should be tracked per slot, per mission, per agent\n- Harness creation and errors should be logged with context\n",
  "fileStats": {
    "size": 14261,
    "lines": 295,
    "lastModified": "2026-01-06T20:09:18.873Z"
  },
  "comments": []
}